{
  "openai": {
    "chat_completion": {
      "id": "chatcmpl-123",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "gpt-4",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "Hello! How can I help you today?"
          },
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 9,
        "completion_tokens": 12,
        "total_tokens": 21
      }
    },
    "with_function_call": {
      "id": "chatcmpl-456",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "gpt-4",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": null,
            "tool_calls": [
              {
                "id": "call_abc123",
                "type": "function",
                "function": {
                  "name": "get_weather",
                  "arguments": "{\"location\": \"San Francisco\"}"
                }
              }
            ]
          },
          "finish_reason": "tool_calls"
        }
      ],
      "usage": {
        "prompt_tokens": 45,
        "completion_tokens": 10,
        "total_tokens": 55
      }
    },
    "error": {
      "error": {
        "message": "Invalid API key",
        "type": "invalid_request_error",
        "param": null,
        "code": "invalid_api_key"
      }
    }
  },
  "anthropic": {
    "message": {
      "id": "msg_01XFDUDYJgAACzvnptvVoYEL",
      "type": "message",
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "Hello! I'm Claude. How can I assist you today?"
        }
      ],
      "model": "claude-3-opus-20240229",
      "stop_reason": "end_turn",
      "usage": {
        "input_tokens": 10,
        "output_tokens": 15
      }
    },
    "with_tool_use": {
      "id": "msg_01ABC",
      "type": "message",
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I'll check the weather for you."
        },
        {
          "type": "tool_use",
          "id": "toolu_01A",
          "name": "get_weather",
          "input": {
            "location": "San Francisco"
          }
        }
      ],
      "model": "claude-3-opus-20240229",
      "stop_reason": "tool_use",
      "usage": {
        "input_tokens": 20,
        "output_tokens": 30
      }
    },
    "error": {
      "type": "error",
      "error": {
        "type": "invalid_request_error",
        "message": "Invalid API key"
      }
    }
  },
  "mistral": {
    "chat_completion": {
      "id": "cmpl-123",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "mistral-large-latest",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "Bonjour! Comment puis-je vous aider?"
          },
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 8,
        "completion_tokens": 10,
        "total_tokens": 18
      }
    }
  },
  "google": {
    "generate_content": {
      "candidates": [
        {
          "content": {
            "parts": [
              {
                "text": "Hello! I'm Gemini. How can I help you today?"
              }
            ],
            "role": "model"
          },
          "finishReason": "STOP",
          "index": 0
        }
      ],
      "usageMetadata": {
        "promptTokenCount": 5,
        "candidatesTokenCount": 12,
        "totalTokenCount": 17
      }
    }
  },
  "cohere": {
    "generate": {
      "id": "gen-123",
      "text": "Hello! I'm Command. How can I assist you?",
      "generation_id": "gen-456",
      "model": "command-r-plus",
      "finish_reason": "COMPLETE",
      "meta": {
        "tokens": {
          "input_tokens": 6,
          "output_tokens": 11
        }
      }
    }
  },
  "xai": {
    "chat_completion": {
      "id": "grok-123",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "grok-beta",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "Hey there! I'm Grok. What's up?"
          },
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 10,
        "total_tokens": 15
      }
    }
  },
  "perplexity": {
    "chat_completion": {
      "id": "pplx-123",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "pplx-70b-online",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "I've searched the web and found the following information..."
          },
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 12,
        "completion_tokens": 20,
        "total_tokens": 32
      }
    }
  },
  "together": {
    "chat_completion": {
      "id": "tog-123",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "Hello from Together.ai!"
          },
          "finish_reason": "eos"
        }
      ],
      "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 8,
        "total_tokens": 13
      }
    }
  },
  "fireworks": {
    "chat_completion": {
      "id": "fw-123",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "accounts/fireworks/models/llama-v2-70b-chat",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "Hello from Fireworks.ai!"
          },
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 6,
        "completion_tokens": 7,
        "total_tokens": 13
      }
    }
  },
  "bedrock": {
    "invoke_model": {
      "output": {
        "message": {
          "role": "assistant",
          "content": [
            {
              "text": "Hello from AWS Bedrock!"
            }
          ]
        }
      },
      "stopReason": "end_turn",
      "usage": {
        "inputTokens": 5,
        "outputTokens": 6
      }
    }
  },
  "ollama": {
    "chat": {
      "model": "llama2",
      "message": {
        "role": "assistant",
        "content": "Hello! I'm running locally via Ollama."
      },
      "done": true,
      "prompt_eval_count": 8,
      "eval_count": 12
    }
  },
  "huggingface": {
    "text_generation": {
      "generated_text": "Hello! I'm a Hugging Face model. How can I help you today?",
      "details": {
        "finish_reason": "stop",
        "generated_tokens": 15,
        "seed": 42
      }
    },
    "chat_completion": {
      "id": "hf-123",
      "model": "mistralai/Mistral-7B-Instruct-v0.2",
      "choices": [
        {
          "index": 0,
          "message": {
            "role": "assistant",
            "content": "Hello! I'm Mistral via Hugging Face Inference API."
          },
          "finish_reason": "stop"
        }
      ],
      "usage": {
        "prompt_tokens": 10,
        "completion_tokens": 12,
        "total_tokens": 22
      }
    },
    "conversational": {
      "generated_text": "That sounds great!",
      "conversation": {
        "past_user_inputs": ["Hi there!"],
        "generated_responses": ["Hello! How are you?"]
      }
    },
    "error": {
      "error": "Model is currently loading. Please retry in a few seconds."
    }
  }
}
